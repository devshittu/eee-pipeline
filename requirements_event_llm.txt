# requirements_event_llm.txt
# File path: requirements_event_llm.txt

fastapi==0.111.0
uvicorn==0.30.1
pydantic==2.7.1
pydantic-settings==2.2.1
torch==2.3.0 # Core dependency for transformers
transformers==4.41.2
accelerate==0.30.1 # For efficient model loading and inference on GPU
bitsandbytes==0.43.1 # For quantization (e.g., if using 8-bit, 4-bit models)
sentencepiece==0.1.99 # For some LLM tokenizers
# Optional: For T5/Flan-T5 models
# einops==0.8.0
# optimum==1.19.0 # For ONNX Runtime or other optimizations
# flash-attn==2.6.0 # If using Flash Attention for speedup on supported GPUs
python-json-logger==2.0.7
PyYAML==6.0.1
tenacity==8.2.3
